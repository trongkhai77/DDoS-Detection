# -*- coding: utf-8 -*-
"""Final_Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ShZU-8hqTirYHlqAd1gxa0M8fcDoyHu3
"""

from pandas import read_csv
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
from xgboost import XGBClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn import svm
from sklearn.naive_bayes import GaussianNB
import numpy as np

from pandas import read_csv
file1 = r"combined_dataset.csv"
df = read_csv(file1, low_memory=False)

df.drop('No.', inplace=True, axis=1)
df['Destination'] = [(str(i).replace('.', '')) for i in df["Destination"]]
df['Source'] = df['Source'].str.replace('.', '').astype(str)
df["Protocol"] = df["Protocol"].replace(['ICMP','LLDP','ARP','ICMPv6','MDNS'],[1,2,3,4,5])
df.drop('Info', inplace= True, axis=1)
df.drop('Source', inplace= True, axis=1)
df.drop('Destination', inplace= True, axis=1)
# print(df.head(10))
# print('------------------------------------------------------------------')
# print(df.info())
# print('------------------------------------------------------------------')
# print(df.iloc[0:10, 3])

def df_to_X_y(df, window_size=3):
    # Convert the input dataframe to a NumPy array for easier manipulation
    df_as_np = df.to_numpy()

    # Initialize empty lists to hold the features (X), labels (y), and indices
    X = []
    y = []
    indices = []

    # Iterate over the length of the dataframe minus the window size
    for i in range(len(df_as_np) - window_size):
        # Extract a 'window' of values from the dataframe (a slice of rows)
        # and format each value as a list (to keep consistent dimensionality)
        row = [[a] for a in df_as_np[i:i + window_size]]

        # Append the windowed rows to the feature list X
        X.append(row)

        # The label (y) is the value that follows the current window
        label = df_as_np[i + window_size]

        # Append the label to the label list y
        y.append(label)

        # Append the starting index of the window to the indices list
        indices.append(df.index[i])

    # Convert the feature (X) and label (y) lists into NumPy arrays and return them along with the indices
    return np.array(X), np.array(y), np.array(indices)

WINDOW_SIZE = 3  # Define the size of the sliding window (number of time steps to consider for each sequence)
temp = df['label']

# X will contain sequences of length 'WINDOW_SIZE', and y will contain the corresponding labels (next values)
X, y, indices = df_to_X_y(temp, WINDOW_SIZE)

# Output the shapes of X and y to check the dimensions
X.shape, y.shape

indices = np.arange(len(X))

# Step 1: Split the dataset into training+validation and test sets, preserving indices
X_train_val, X_test, y_train_val, y_test, indices_train_val, indices_test = train_test_split(
    X, y, indices, test_size=0.3, random_state=0
)

# Step 2: Split the training+validation set into training and validation sets, preserving indices
X_train, X_val, y_train, y_val, indices_train, indices_val = train_test_split(
    X_train_val, y_train_val, indices_train_val,
    test_size=0.25, random_state=0, shuffle=True, stratify=y_train_val
)

X_train_flattened = X_train.reshape(X_train.shape[0], -1)
X_test_flattened = X_test.reshape(X_test.shape[0], -1)
X_val_flattened = X_test.reshape(X_test.shape[0], -1)

# Import KNeighborsClassifier from sklearn.neighbors
from sklearn.neighbors import KNeighborsClassifier

# Create a k-NN classifier with 3 neighbors
knn = KNeighborsClassifier(n_neighbors = 3)

# Fit the classifier to the data
knn.fit(X_train_flattened,y_train)

# 80% training and 20% test
y_pred_val = knn.predict(X_val_flattened)

accuracy_val_KNN = accuracy_score(y_test, y_pred_val)
precision_val_KNN = precision_score(y_test, y_pred_val)
recall_val_KNN = recall_score(y_test, y_pred_val)
f1_val_KNN = f1_score(y_test, y_pred_val)
print("Accuracy:",accuracy_val_KNN)
print("Precision:", precision_val_KNN)
print("Recall:", recall_val_KNN)
print("F1-score:", f1_val_KNN)

def create_input_sequence(data, window_size):
    if len(data) < window_size:
        raise ValueError("Không đủ dữ liệu để tạo chuỗi đầu vào với window_size đã cho.")
    input_sequence = np.array(data[-window_size:]).reshape(1, -1)
    return input_sequence

# Lấy 20 điểm dữ liệu gần nhất từ bộ dữ liệu gốc
last_20_points = df['label'][-20:].values

X_new = create_input_sequence(last_20_points, WINDOW_SIZE)

# Dự đoán giá trị label tiếp theo
rf_classifier = RandomForestClassifier(random_state=0)
rf_classifier.fit(X_train_flattened, y_train)
prediction = rf_classifier.predict(X_new)[0]

print("Dự đoán: " + str(prediction))

import joblib

# Sau khi train xong các model
joblib.dump(knn, 'knn_model.joblib')
joblib.dump(rf_classifier, 'rf_model.joblib')
print("Saved models successfully")